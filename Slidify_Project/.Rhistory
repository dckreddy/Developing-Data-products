effectData$CROPDMGEXP[effectData$CROPDMGEXP=="B"|effectData$CROPDMGEXP=="b"] <- 10^9;
effectData$CROPDMGEXP <- gsub("\\-|\\+|\\?|0","0",effectData$CROPDMGEXP)
effectData$CROPDMGEXP[is.na(effectData$CROPDMGEXP)] <- 0;
effectData$CROPDMG[is.na(effectData$CROPDMG)] <- 0;
effectData$CROPDMGEXP <- as.numeric(effectData$CROPDMGEXP)
effectData <- mutate(effectData, CROPCOST = CROPDMG * CROPDMGEXP)
TOTALCROPCOST<- as.data.frame(aggregate(effectData$CROPCOST, list(effectData$EVTYPE), sum))
names(TOTALCROPCOST)<-c("EVENT", "CROPCOST")
head(effectData,10)
DAMAGEDATA <- summarize(group_by(effectData, EVTYPE), TOTAL.PROPDAMAGE = sum(PROPCOST), TOTAL.CROPDAMAGE = sum(CROPCOST))
head(DAMAGEDATA)
head(DAMAGEDATA,10)
PROPDATA <- DAMAGEDATA[order(-DAMAGEDATADATA[, 2]), ][1:10, c(1,2)]
PROPDATA
g1<-ggplot(data = PROPDATA, aes(y=TOTAL.PROPDAMAGE,
x=reorder(EVTYPE, TOTAL.PROPDAMAGE))) +
geom_bar(stat="identity", fill="darkgreen") +coord_flip()+
ylab("Total Property Damages")+
xlab("Event Type")+
ggtitle("Top Event Types Vs Total Property Damages")
g1
PROPDATA <- DAMAGEDATA[order(-DAMAGEDATADATA[, 2]), ][1:10, c(1,2)]
PROPDATA
g1<-ggplot(data = PROPDATA, aes(y=TOTAL.PROPDAMAGE,
x=reorder(EVTYPE, TOTAL.PROPDAMAGE))) +
geom_bar(stat="identity", fill="darkgreen") +coord_flip()+
ylab("Total Property Damages")+
xlab("Event Type")+
ggtitle("Top Event Types Vs Total Property Damages")
g1
PROPDATA <- DAMAGEDATA[order(-DAMAGEDATA[, 2]), ][1:10, c(1,2)]
PROPDATA
g1<-ggplot(data = PROPDATA, aes(y=TOTAL.PROPDAMAGE,
x=reorder(EVTYPE, TOTAL.PROPDAMAGE))) +
geom_bar(stat="identity", fill="darkgreen") +coord_flip()+
ylab("Total Property Damages")+
xlab("Event Type")+
ggtitle("Top Event Types Vs Total Property Damages")
g1
CROPDATA <- DAMAGEDATA[order(-DAMAGEDATA[, 3]), ][1:10, c(1,3)]
CROPDATA
g2<-ggplot(data = CROPDATA, aes(y=TOTAL.CROPDAMAGE/10^9,
x=reorder(EVTYPE, TOTAL.CROPDAMAGE))) +
geom_bar(stat="identity", fill="darkgreen") +coord_flip()+
ylab("Total Crop Damages (in Billion Dollars)")+
xlab("Event Type")+
ggtitle("Top Event Types Vs Total Crop Damages")
g2
TOTALDAMAGEDT <- summarize(group_by(effectData, EVTYPE), TOTALCOST = sum(PROPCOST+CROPCOST))
TOTALDAMAGE <- TOTALDAMAGEDT[order(-TOTALDAMAGEDT[, 2]), ][1:10, ]
g3 <-ggplot(data = TOTALDAMAGE, aes(y=TOTALCOST/10^9,
x=reorder(EVTYPE, TOTALCOST))) +
geom_bar(stat="identity", fill="darkgreen") +coord_flip()+
ylab("Total Damages (in Billion Dollars)")+
xlab("Event Type")+
ggtitle("Top Event Types Vs Total Damages")
g3
bzfilenm <- "StormData.csv.bz2"
if (!file.exists(bzfilenm)) {
download.file("http://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2", destfile=bzfilenm)
stormdata <- read.csv(bzfile(bzfilenm))
} else message("Storm data already loaded")
message("Storm Data frame has ", nrow(stormdata), " rows and ", ncol(stormdata), " columns")
names(stormdata)
effectData <- subset(stormdata, select = c("EVTYPE", "FATALITIES", "INJURIES", "PROPDMG",
"PROPDMGEXP", "CROPDMG", "CROPDMGEXP"))
effectData$EVTYPE <- toupper(effectData$EVTYPE)
unique(effectData$PROPDMGEXP)
effectData$PROPDMGEXP[effectData$PROPDMGEXP=="H"|effectData$PROPDMGEXP=="h"] <- 10^2;
effectData$PROPDMGEXP[effectData$PROPDMGEXP=="K"|effectData$PROPDMGEXP=="k"] <- 10^3;
effectData$PROPDMGEXP[effectData$PROPDMGEXP=="M"|effectData$PROPDMGEXP=="m"] <- 10^6;
effectData$PROPDMGEXP[effectData$PROPDMGEXP=="B"|effectData$PROPDMGEXP=="b"] <- 10^9;
effectData$PROPDMGEXP <- gsub("\\-|\\+|\\?|0","0",effectData$PROPDMGEXP)
effectData$PROPDMGEXP[is.na(effectData$PROPDMGEXP)] <- 0;
effectData$PROPDMG[is.na(effectData$PROPDMG)] <- 0;
effectData$PROPDMGEXP <- as.numeric(effectData$PROPDMGEXP)
effectData <- mutate(effectData, PROPCOST = PROPDMG * PROPDMGEXP)
TOTALPROPCOST<- as.data.frame(aggregate(effectData$PROPCOST, list(effectData$EVTYPE), sum))
names(TOTALPROPCOST)<-c("EVENT", "PROPCOST")
bzfilenm <- "StormData.csv.bz2"
if (!file.exists(bzfilenm)) {
download.file("http://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2", destfile=bzfilenm)
stormdata <- read.csv(bzfile(bzfilenm),stringsAsFactors = FALSE)
} else message("Storm data already loaded")
message("Storm Data frame has ", nrow(stormdata), " rows and ", ncol(stormdata), " columns")
names(stormdata)
effectData <- subset(stormdata, select = c("EVTYPE", "FATALITIES", "INJURIES", "PROPDMG",
"PROPDMGEXP", "CROPDMG", "CROPDMGEXP"))
unique(effectData$PROPDMGEXP)
effectData$PROPDMGEXP[effectData$PROPDMGEXP=="H"|effectData$PROPDMGEXP=="h"] <- 10^2;
effectData$PROPDMGEXP[effectData$PROPDMGEXP=="K"|effectData$PROPDMGEXP=="k"] <- 10^3;
effectData$PROPDMGEXP[effectData$PROPDMGEXP=="M"|effectData$PROPDMGEXP=="m"] <- 10^6;
effectData$PROPDMGEXP[effectData$PROPDMGEXP=="B"|effectData$PROPDMGEXP=="b"] <- 10^9;
effectData$PROPDMGEXP <- gsub("\\-|\\+|\\?|0","0",effectData$PROPDMGEXP)
effectData$PROPDMGEXP[is.na(effectData$PROPDMGEXP)] <- 0;
effectData$PROPDMG[is.na(effectData$PROPDMG)] <- 0;
effectData$PROPDMGEXP <- as.numeric(effectData$PROPDMGEXP)
effectData <- mutate(effectData, PROPCOST = PROPDMG * PROPDMGEXP)
TOTALPROPCOST<- as.data.frame(aggregate(effectData$PROPCOST, list(effectData$EVTYPE), sum))
names(TOTALPROPCOST)<-c("EVENT", "PROPCOST")
unique(effectData$CROPDMGEXP)
effectData$CROPDMGEXP[effectData$CROPDMGEXP=="H"|effectData$CROPDMGEXP=="h"] <- 10^2;
effectData$CROPDMGEXP[effectData$CROPDMGEXP=="K"|effectData$CROPDMGEXP=="k"] <- 10^3;
effectData$CROPDMGEXP[effectData$CROPDMGEXP=="M"|effectData$CROPDMGEXP=="m"] <- 10^6;
effectData$CROPDMGEXP[effectData$CROPDMGEXP=="B"|effectData$CROPDMGEXP=="b"] <- 10^9;
effectData$CROPDMGEXP <- gsub("\\-|\\+|\\?|0","0",effectData$CROPDMGEXP)
effectData$CROPDMGEXP[is.na(effectData$CROPDMGEXP)] <- 0;
effectData$CROPDMG[is.na(effectData$CROPDMG)] <- 0;
effectData$CROPDMGEXP <- as.numeric(effectData$CROPDMGEXP)
effectData <- mutate(effectData, CROPCOST = CROPDMG * CROPDMGEXP)
TOTALCROPCOST<- as.data.frame(aggregate(effectData$CROPCOST, list(effectData$EVTYPE), sum))
names(TOTALCROPCOST)<-c("EVENT", "CROPCOST")
library(plyr)
library(dplyr)
library(reshape2)
library(ggplot2)
HARMDATA <- summarize(group_by(effectData, EVTYPE), TOTAL.INJURIES = sum(INJURIES), TOTAL.FATALITIES = sum(FATALITIES))
FATALDATA <- HARMDATA[order(-HARMDATA[, 3]), ][1:10, c(1,3)]
FATALDATA
g1<-ggplot(data = FATALDATA, aes(y=TOTAL.FATALITIES,
x=reorder(EVTYPE, TOTAL.FATALITIES))) +
geom_bar(stat="identity", fill="darkgreen") +coord_flip()+
ylab("Total Fatalities")+
xlab("Event Type")+
ggtitle("Top Event Types Vs Total Fatalities")
g1
INJURDATA <- HARMDATA[order(-HARMDATA[, 2]), ][1:10, c(1,2)]
INJURDATA
g2<-ggplot(data = INJURDATA, aes(y=TOTAL.INJURIES,
x=reorder(EVTYPE, TOTAL.INJURIES))) +
geom_bar(stat="identity", fill="darkblue")+ coord_flip()+
ylab("Total Injuries")+
xlab("Event Type") +
ggtitle("Top Event Types Vs Total Injuries")
g2
DAMAGEDATA <- summarize(group_by(effectData, EVTYPE), TOTAL.PROPDAMAGE = sum(PROPCOST), TOTAL.CROPDAMAGE = sum(CROPCOST))
PROPDATA <- DAMAGEDATA[order(-DAMAGEDATA[, 2]), ][1:10, c(1,2)]
PROPDATA
g1<-ggplot(data = PROPDATA, aes(y=TOTAL.PROPDAMAGE/10^6,
x=reorder(EVTYPE, TOTAL.PROPDAMAGE))) +
geom_bar(stat="identity", fill="darkblue") +coord_flip()+
ylab("Total Property Damages (US Million Dollars)")+
xlab("Event Type")+
ggtitle("Top Event Types Vs Total Property Damages")
g1
PROPDATA <- DAMAGEDATA[order(-DAMAGEDATA[, 2]), ][1:10, c(1,2)]
PROPDATA
g1<-ggplot(data = PROPDATA, aes(y=TOTAL.PROPDAMAGE/10^9,
x=reorder(EVTYPE, TOTAL.PROPDAMAGE))) +
geom_bar(stat="identity", fill="darkblue") +coord_flip()+
ylab("Total Property Damages (US Billion Dollars)")+
xlab("Event Type")+
ggtitle("Top Event Types Vs Total Property Damages")
g1
CROPDATA <- DAMAGEDATA[order(-DAMAGEDATA[, 3]), ][1:10, c(1,3)]
CROPDATA
g2<-ggplot(data = CROPDATA, aes(y=TOTAL.CROPDAMAGE/10^6,
x=reorder(EVTYPE, TOTAL.CROPDAMAGE))) +
geom_bar(stat="identity", fill="darkgreen") +coord_flip()+
ylab("Total Crop Damages (US Million Dollars)")+
xlab("Event Type")+
ggtitle("Top Event Types Vs Total Crop Damages")
g2
TOTALDAMAGEDT <- summarize(group_by(effectData, EVTYPE), TOTALCOST = sum(PROPCOST+CROPCOST))
TOTALDAMAGE <- TOTALDAMAGEDT[order(-TOTALDAMAGEDT[, 2]), ][1:10, ]
g3 <-ggplot(data = TOTALDAMAGE, aes(y=TOTALCOST/10^9,
x=reorder(EVTYPE, TOTALCOST))) +
geom_bar(stat="identity", fill="darkgreen") +coord_flip()+
ylab("Total Damages (US Billion Dollars)")+
xlab("Event Type")+
ggtitle("Top Event Types Vs Total Damages")
g3
TOTALDAMAGEDT <- summarize(group_by(effectData, EVTYPE), TOTALCOST = sum(PROPCOST+CROPCOST))
TOTALDAMAGE <- TOTALDAMAGEDT[order(-TOTALDAMAGEDT[, 2]), ][1:10, ]
g3 <-ggplot(data = TOTALDAMAGE, aes(y=TOTALCOST/10^6,
x=reorder(EVTYPE, TOTALCOST))) +
geom_bar(stat="identity", fill="darkgreen") +coord_flip()+
ylab("Total Damages (US Million Dollars)")+
xlab("Event Type")+
ggtitle("Top Event Types Vs Total Damages")
g3
bzfilenm <- "StormData.csv.bz2"
if (!file.exists(bzfilenm)) {
download.file("http://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2", destfile=bzfilenm)
stormdata <- read.csv(bzfile(bzfilenm),stringsAsFactors = FALSE)
} else message("Storm data already loaded")
message("Storm Data frame has ", nrow(stormdata), " rows and ", ncol(stormdata), " columns")
names(stormdata)
getwd()
## Loading Libraries
library(plyr)
library(reshape2)
## Import the test data
X_test<-read.table("./UCI HAR Dataset/test/X_test.txt")
Y_test<-read.table("./UCI HAR Dataset/test/y_test.txt")
subject_test<-read.table("./UCI HAR Dataset/test/subject_test.txt")
## Import the training data
X_train<-read.table("./UCI HAR Dataset/train/X_train.txt")
Y_train<-read.table("./UCI HAR Dataset/train/y_train.txt")
subject_train<-read.table("./UCI HAR Dataset/train/subject_train.txt")
## 1. Merge the training and test sets to create one data set.
## Combine the X data, Y data, and subject row identification into full versions of each
X_full<-rbind(X_test, X_train)
Y_full<-rbind(Y_test, Y_train)
subject_full<-rbind(subject_test, subject_train)
## Now the data frames are joined, it's worth naming the columns in x_full from features.txt
features <- read.table("./UCI HAR Dataset/features.txt")
colnames(X_full)<-features[,2]
## 2. Extract only the measurements on the mean and standard deviation for each measurement
rightcols<- grepl("mean()",colnames(X_full)) | grepl("std()",colnames(X_full))
X_mean_std <- X_full[,rightcols]
## 3. Uses descriptive activity names to name the activities in the data set
activities<-read.table("./UCI HAR Dataset/activity_labels.txt")
## While translating Y_full into human readable names I'l also make it a factor.
Y_factor <- as.factor(Y_full[,1])
Y_factor <- mapvalues(Y_factor,from = as.character(activities[,1]), to = as.character(activities[,2]))
## 4. Appropriately labels the data set with descriptive activity names.
X_mean_std <- cbind(Y_factor, X_mean_std)
colnames(X_mean_std)[1] <- "activity"
X_mean_std <- cbind(subject_full, X_mean_std)
colnames(X_mean_std)[1] <- "subject"
## 5. Creates a second, independent tidy data set with the average of each variable for each activity and each
## subject.
X_melt<- melt(X_mean_std,id.vars=c("subject","activity"))
Xav_tidy <- dcast(X_melt, subject + activity ~ ..., mean)
## Loading Libraries
library(plyr)
library(reshape2)
## Import the test data
X_test<-read.table("UCI HAR Dataset/test/X_test.txt")
Y_test<-read.table("UCI HAR Dataset/test/y_test.txt")
subject_test<-read.table("UCI HAR Dataset/test/subject_test.txt")
## Import the training data
X_train<-read.table("UCI HAR Dataset/train/X_train.txt")
Y_train<-read.table("UCI HAR Dataset/train/y_train.txt")
subject_train<-read.table("UCI HAR Dataset/train/subject_train.txt")
X_test<-read.table("~/UCI HAR Dataset/test/X_test.txt")
Y_test<-read.table("~/UCI HAR Dataset/test/y_test.txt")
subject_test<-read.table("~/UCI HAR Dataset/test/subject_test.txt")
setwd("C:\\Users\\chaitanya")
X_test<-read.table("~/UCI HAR Dataset/test/X_test.txt")
Y_test<-read.table("~/UCI HAR Dataset/test/y_test.txt")
subject_test<-read.table("~/UCI HAR Dataset/test/subject_test.txt")
X_test<-read.table("./UCI HAR Dataset/test/X_test.txt")
## Loading Libraries
library(plyr)
library(reshape2)
## Import the test data
X_test<-read.table("./UCI HAR Dataset/test/X_test.txt")
Y_test<-read.table("./UCI HAR Dataset/test/y_test.txt")
subject_test<-read.table("./UCI HAR Dataset/test/subject_test.txt")
## Import the training data
X_train<-read.table("./UCI HAR Dataset/train/X_train.txt")
Y_train<-read.table("./U0CI HAR Dataset/train/y_train.txt")
subject_train<-read.table("./UCI HAR Dataset/train/subject_train.txt")
## 1. Merge the training and test sets to create one data set.
## Combine the X data, Y data, and subject row identification into full versions of each
X_full<-rbind(X_test, X_train)
Y_full<-rbind(Y_test, Y_train)
subject_full<-rbind(subject_test, subject_train)
## Now the data frames are joined, it's worth naming the columns in x_full from features.txt
features <- read.table("./UCI HAR Dataset/features.txt")
colnames(X_full)<-features[,2]
## 2. Extract only the measurements on the mean and standard deviation for each measurement
rightcols<- grepl("mean()",colnames(X_full)) | grepl("std()",colnames(X_full))
X_mean_std <- X_full[,rightcols]
## 3. Uses descriptive activity names to name the activities in the data set
activities<-read.table("./UCI HAR Dataset/activity_labels.txt")
Y_factor <- as.factor(Y_full[,1])
Y_factor <- mapvalues(Y_factor,from = as.character(activities[,1]), to = as.character(activities[,2]))
## 4. Appropriately labels the data set with descriptive activity names.
X_mean_std <- cbind(Y_factor, X_mean_std)
colnames(X_mean_std)[1] <- "activity"
X_mean_std <- cbind(subject_full, X_mean_std)
colnames(X_mean_std)[1] <- "subject"
## 5. Creates a second, independent tidy data set with the average of each variable for each activity and each subject.
X_melt<- melt(X_mean_std,id.vars=c("subject","activity"))
Xav_tidy <- dcast(X_melt, subject + activity ~ ..., mean)
Y_train<-read.table("./U0CI HAR Dataset/train/y_train.txt")
Y_train<-read.table("./UCI HAR Dataset/train/y_train.txt")
Y_train<-read.table("./UCI HAR Dataset/train/y_train.txt")
## Loading Libraries
library(plyr)
library(reshape2)
## Import the test data
X_test<-read.table("./UCI HAR Dataset/test/X_test.txt")
Y_test<-read.table("./UCI HAR Dataset/test/y_test.txt")
subject_test<-read.table("./UCI HAR Dataset/test/subject_test.txt")
## Import the training data
X_train<-read.table("./UCI HAR Dataset/train/X_train.txt")
Y_train<-read.table("./UCI HAR Dataset/train/y_train.txt")
subject_train<-read.table("./UCI HAR Dataset/train/subject_train.txt")
## 1. Merge the training and test sets to create one data set.
## Combine the X data, Y data, and subject row identification into full versions of each
X_full<-rbind(X_test, X_train)
Y_full<-rbind(Y_test, Y_train)
subject_full<-rbind(subject_test, subject_train)
## Now the data frames are joined, it's worth naming the columns in x_full from features.txt
features <- read.table("./UCI HAR Dataset/features.txt")
colnames(X_full)<-features[,2]
## 2. Extract only the measurements on the mean and standard deviation for each measurement
rightcols<- grepl("mean()",colnames(X_full)) | grepl("std()",colnames(X_full))
X_mean_std <- X_full[,rightcols]
## 3. Uses descriptive activity names to name the activities in the data set
activities<-read.table("./UCI HAR Dataset/activity_labels.txt")
Y_factor <- as.factor(Y_full[,1])
Y_factor <- mapvalues(Y_factor,from = as.character(activities[,1]), to = as.character(activities[,2]))
## 4. Appropriately labels the data set with descriptive activity names.
X_mean_std <- cbind(Y_factor, X_mean_std)
colnames(X_mean_std)[1] <- "activity"
X_mean_std <- cbind(subject_full, X_mean_std)
colnames(X_mean_std)[1] <- "subject"
## 5. Creates a second, independent tidy data set with the average of each variable for each activity and each subject.
X_melt<- melt(X_mean_std,id.vars=c("subject","activity"))
Xav_tidy <- dcast(X_melt, subject + activity ~ ..., mean)
xav_tidy
Xav_tidy
head(Xav_tidy)
X_mean_std
X_mean_std[,1]
head(X_mean_std[,1],10)
averages_data <- ddply(X_mean_std, .(subject, activity), function(x) colMeans(x[, 1:66]))
write.table(averages_data, "averages_data.txt", row.name=FALSE)
## Loading Libraries
library(plyr)
library(reshape2)
## Import the test data
X_test<-read.table("./UCI HAR Dataset/test/X_test.txt")
Y_test<-read.table("./UCI HAR Dataset/test/y_test.txt")
subject_test<-read.table("./UCI HAR Dataset/test/subject_test.txt")
## Import the training data
X_train<-read.table("./UCI HAR Dataset/train/X_train.txt")
Y_train<-read.table("./UCI HAR Dataset/train/y_train.txt")
subject_train<-read.table("./UCI HAR Dataset/train/subject_train.txt")
## 1. Merge the training and test sets to create one data set.
## Combine the X data, Y data, and subject row identification into full versions of each
X_full<-rbind(X_test, X_train)
Y_full<-rbind(Y_test, Y_train)
subject_full<-rbind(subject_test, subject_train)
## Now the data frames are joined, it's worth naming the columns in x_full from features.txt
features <- read.table("./UCI HAR Dataset/features.txt")
colnames(X_full)<-features[,2]
## 2. Extract only the measurements on the mean and standard deviation for each measurement
rightcols<- grepl("mean()",colnames(X_full)) | grepl("std()",colnames(X_full))
X_mean_std <- X_full[,rightcols]
## 3. Uses descriptive activity names to name the activities in the data set
activities<-read.table("./UCI HAR Dataset/activity_labels.txt")
Y_factor <- as.factor(Y_full[,1])
Y_factor <- mapvalues(Y_factor,from = as.character(activities[,1]), to = as.character(activities[,2]))
## 4. Appropriately labels the data set with descriptive activity names.
X_mean_std <- cbind(Y_factor, X_mean_std)
colnames(X_mean_std)[1] <- "activity"
X_mean_std <- cbind(subject_full, X_mean_std)
colnames(X_mean_std)[1] <- "subject"
## 5. Creates a second, independent tidy data set with the average of each variable for each activity and each subject.
X_melt<- melt(X_mean_std,id.vars=c("subject","activity"))
Xav_tidy <- dcast(X_melt, subject + activity ~ ..., mean)
## Loading Libraries
library(plyr)
library(reshape2)
## Import the test data
X_test<-read.table("./UCI HAR Dataset/test/X_test.txt")
Y_test<-read.table("./UCI HAR Dataset/test/y_test.txt")
subject_test<-read.table("./UCI HAR Dataset/test/subject_test.txt")
## Import the training data
X_train<-read.table("./UCI HAR Dataset/train/X_train.txt")
Y_train<-read.table("./UCI HAR Dataset/train/y_train.txt")
subject_train<-read.table("./UCI HAR Dataset/train/subject_train.txt")
## 1. Merge the training and test sets to create one data set.
## Combine the X data, Y data, and subject row identification into full versions of each
X_full<-rbind(X_test, X_train)
Y_full<-rbind(Y_test, Y_train)
subject_full<-rbind(subject_test, subject_train)
## Now the data frames are joined, it's worth naming the columns in x_full from features.txt
features <- read.table("./UCI HAR Dataset/features.txt")
colnames(X_full)<-features[,2]
## 2. Extract only the measurements on the mean and standard deviation for each measurement
rightcols<- grepl("mean()",colnames(X_full)) | grepl("std()",colnames(X_full))
X_mean_std <- X_full[,rightcols]
## 3. Uses descriptive activity names to name the activities in the data set
activities<-read.table("./UCI HAR Dataset/activity_labels.txt")
Y_factor <- as.factor(Y_full[,1])
Y_factor <- mapvalues(Y_factor,from = as.character(activities[,1]), to = as.character(activities[,2]))
## 4. Appropriately labels the data set with descriptive activity names.
X_mean_std <- cbind(Y_factor, X_mean_std)
colnames(X_mean_std)[1] <- "activity"
X_mean_std <- cbind(subject_full, X_mean_std)
colnames(X_mean_std)[1] <- "subject"
## 5. Creates a second, independent tidy data set with the average of each variable for each activity and each subject.
X_melt<- melt(X_mean_std,id.vars=c("subject","activity"))
Xav_tidy <- dcast(X_melt, subject + activity ~ ..., mean)
write.table(Xav_tidy, "averages_data.txt", row.name=FALSE)
getwd()
install.packages("devtools")
library(devtools)
install_github('slidify','ramnathv')
install_github('slidify')
install_github('slidifyLibraries','ramnathv')
install.packages("shiny")
library(shiny)
library(slidify)
libary(UsingR)
install.packages("UsingR")
library(UsingR)
setwd("C:\\Users\\chaitanya\\shinyApp")
runApp()
install.packages("AppliedPredictiveModeling")
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
install.packages("caret")
library(caret)
install.packages("rattle")
library(rattle)
install.packages("rpart.plot")
library(rpart.plot)
install.packages("randomForest")
library(randomForest)
install.packages("e1071")
library(e1071)
devtools::install_github('rstudio/shinyapps')
getwd()
setwd("C://Users//chaitanya")
devtools::install_github('rstudio/shinyapps')
install.packages("devtools")
install.packages("devtools")
install.packages('devtools')
install.packages('devtools')
install.packages("devtools")
devtools::install_github('rstudio/shinyapps')
shinyapps::setAccountInfo(name='dckreddy',
token='097AFC4020825779572EBDF9D4B8B7FD',
secret='xgDW7Os7ogJlLUS5JGvvoi4AcQoAMMrTENVHcPZR')
library(shinyapps)
shinyapps::deployApp('C:\\Users\\chaitanya\\Developing-Data-products\\shinyApp_Project')
install.packages('shiny')
install.packages('UsingR')
library(UsingR)
library(shiny)
shinyapps::deployApp('C:\\Users\\chaitanya\\Developing-Data-products\\shinyApp_Project')
u <- runif(10)
punif(10)
library(slidify)
getwd()
setwd("C:\\Users\\chaitanya\\Developing-Data-products\\Slidify_Project")
install.packages("slidify")
library(devtools)
install_github('slidify','ramnathv')
library(slidify)
author("mydeck")
install.packages("slidifyLibraries")
library(slidifyLibraries)
install.packages('slidifyLibraries')
library(slidifyLibraries)
library(slidifyLibraries)
library(slidifylibraries)
install.packages('slidifylibraries')
require(devtools)
install_github("slidify", "ramnathv")
install_github("slidifyLibraries", "ramnathv")
library(slidify)
slidify("index.Rmd")
publish(user = "dckreddy", repo = "https://github.com/dckreddy/Developing-Data-products/tree/gh-pages/Slidify_Project")
publish(user = "dckreddy", repo = "https://github.com/dckreddy/Developing-Data-products/Slidify_Project")
subtitle    : Uniform Distribution
author      :
---
### Math Formulae
publish(user = "dckreddy", repo = "https://github.com/dckreddy/Developing-Data-products")
publish(user = "dckreddy", repo = "https://github.com/dckreddy/Developing-Data-products/")
mode        : selfcontained # {standalone, draft}
author("Slidify_Project")
getwd()
setwd("C://Users//chaitanya//Developing-Data-products")
author("Slidify_Project")
2. http://slidify.org/start.html
---
title       : Developing Data Products - Course Project
subtitle    :
author      : Chaitanya Duvvuru
job         :
framework   : io2012        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme     : tomorrow      #
widgets     : [mathjax]            # {mathjax, quiz, bootstrap}
mode        : selfcontained # {standalone, draft}
knit        : slidify::knit2slides
---
## Uniform Distribution presentation
This presentation
1. Gives an overview of Uniform Distribution.
2. Explains probability Distribution function with a mathematical fomula.
3. provides R code commands for Uniform Distribution.
--- .class #id
## Math Formulae
1. Uniform distribution random variable is the form $U(a,b)$
2. Probability Distribution Function  is $f(x)=\frac{1}{b-a}$ for a <= x <= b;
0 for x < a or x > b
--- .class #id
## R code
The probability is calculated using R function punif()
```{r, echo=TRUE}
u <- runif(10)
punif(u)
```
--- .class #id
## References
1. http://astrostatistics.psu.edu/su07/R/html/stats/html/Uniform.html
2. http://slidify.org/start.html
3. http://slidify.org/samples/
--- .class #id
## Thank you!
This is the last slide. Hope you enjoyed this App.
